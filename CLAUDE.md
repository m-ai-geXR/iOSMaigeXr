# CLAUDE.md - iOS XRAiAssistant

This file provides guidance to Claude Code (claude.ai/code) when working with the iOS implementation of XRAiAssistant.

**XRAiAssistant iOS** is an AI-powered Extended Reality development platform that combines Babylon.js, Together AI, React Three Fiber, and native iOS development into the ultimate mobile XR development environment with advanced AI assistance capabilities.

> **The Ultimate Mobile XR Development Environment for iOS**
> Democratizing 3D and Extended Reality development through conversational AI assistance, professional parameter control, and privacy-first architecture.

---

## üö® CRITICAL FIXES (2025-11-22)

### Fix #1: Parameter Order Error ‚úÖ

**Issue**: SwiftCompile failed with "Argument 'maxTokens' must precede argument 'stream'"

**Root Cause**: The AIProxy library's `TogetherAIChatCompletionRequestBody` requires `maxTokens` parameter to come before `stream` parameter.

**Files Modified**:
- ‚úÖ [XRAiAssistant/AIProviders/TogetherAIProvider.swift:88-95](XRAiAssistant/AIProviders/TogetherAIProvider.swift#L88-L95)
- ‚úÖ [XRAiAssistant/ChatViewModel.swift:599-606](XRAiAssistant/ChatViewModel.swift#L599-L606)

**The Fix**:
```swift
// CORRECT parameter order
let requestBody = TogetherAIChatCompletionRequestBody(
    messages: togetherMessages,
    model: model,
    maxTokens: 4000,  // ‚úÖ MUST come before stream
    stream: true,
    temperature: temperature,
    topP: topP
)
```

### Fix #2: Non-Serverless Model Error ‚úÖ

**Issue**: Together AI returned 400 error: "Unable to access non-serverless model Qwen/Qwen2.5-Coder-32B-Instruct"

**Root Cause**: The Qwen 2.5 Coder 32B model requires a dedicated endpoint and is not available as a serverless model on Together.ai.

**Files Modified**:
- ‚úÖ [XRAiAssistant/ChatViewModel.swift:86-94](XRAiAssistant/ChatViewModel.swift#L86-L94)

**The Fix**: Removed `Qwen/Qwen2.5-Coder-32B-Instruct` from `availableModels` array. Only serverless models are now included:

```swift
let availableModels = [
    "deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free", // FREE
    "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",   // FREE
    "meta-llama/Meta-Llama-3-8B-Instruct-Lite",       // $0.10/1M
    "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",    // $0.18/1M
    "Qwen/Qwen2.5-7B-Instruct-Turbo"                  // $0.30/1M
]
```

**User Action Required**: If you previously selected "Qwen 2.5 Coder 32B" in Settings, please switch to one of the FREE models:
- DeepSeek R1 70B (recommended for coding)
- Meta Llama 3.3 70B

**Why This Fixes 400 Errors**:
- Together AI API expects `max_tokens` parameter in requests
- AIProxy Swift library maps `maxTokens` to `max_tokens` in the JSON request
- Without this parameter, the API returns 400 Bad Request
- Setting it to 4000 matches the pattern used in AnthropicProvider (line 100)

**Verification**:
- Check logs for: `üîß Together.ai config: stream=true, temperature=X, top-p=X, max-tokens=4000`
- API requests should now succeed with 200 OK responses
- Streaming responses will be properly received

---

## ‚öôÔ∏è BUILD REQUIREMENTS - MANDATORY

### **CRITICAL**: Always Run Build After Code Changes

After making ANY code changes, you MUST verify the project builds successfully:

```bash
# Quick build verification (REQUIRED)
xcodebuild -project XRAiAssistant.xcodeproj \
  -scheme XRAiAssistant \
  -configuration Debug \
  -sdk iphonesimulator \
  build \
  CODE_SIGN_IDENTITY="" \
  CODE_SIGNING_REQUIRED=NO \
  2>&1 | grep -E "(error:|warning:|Build succeeded|BUILD FAILED)"
```

**Expected Output**: `** BUILD SUCCEEDED **`

**If Build Fails**:
1. Read the error messages carefully
2. Fix the errors (common: parameter order, missing imports, syntax errors)
3. Run build again
4. Repeat until build succeeds

**Common Build Issues**:
- Parameter order errors (e.g., `maxTokens` must precede `stream`)
- Missing package dependencies (resolve in Xcode)
- Corrupted DerivedData (clean: `rm -rf ~/Library/Developer/Xcode/DerivedData/XRAiAssistant-*`)

---

## üì± iOS Project Structure

### Main Application (`XRAiAssistant/`)
```
XRAiAssistant/
‚îú‚îÄ‚îÄ XRAiAssistant.swift              # App entry point
‚îú‚îÄ‚îÄ ContentView.swift                # Main UI with bottom navigation
‚îú‚îÄ‚îÄ ChatViewModel.swift              # AI integration + state management (LEGACY)
‚îú‚îÄ‚îÄ AIProviders/                     # NEW: Multi-provider system
‚îÇ   ‚îú‚îÄ‚îÄ AIProvider.swift            # Protocol definitions
‚îÇ   ‚îú‚îÄ‚îÄ AIProviderManager.swift     # Provider routing and management
‚îÇ   ‚îú‚îÄ‚îÄ TogetherAIProvider.swift    # Together.ai implementation (FIXED ‚úÖ)
‚îÇ   ‚îî‚îÄ‚îÄ AnthropicProvider.swift     # Anthropic Claude implementation
‚îú‚îÄ‚îÄ Library3D/                       # 3D framework integrations
‚îÇ   ‚îú‚îÄ‚îÄ Library3DManager.swift      # Framework selection
‚îÇ   ‚îú‚îÄ‚îÄ BabylonJSLibrary.swift      # Babylon.js support
‚îÇ   ‚îú‚îÄ‚îÄ ReactThreeFiberLibrary.swift # React Three Fiber support
‚îÇ   ‚îî‚îÄ‚îÄ ReactylonLibrary.swift      # Reactylon (React Babylon) support
‚îú‚îÄ‚îÄ BuildKit/                        # Advanced build system
‚îÇ   ‚îú‚îÄ‚îÄ BuildManager.swift          # Orchestrates builds
‚îÇ   ‚îú‚îÄ‚îÄ NodeBuildService.swift      # Node.js build environment
‚îÇ   ‚îî‚îÄ‚îÄ WasmBuildService.swift      # WebAssembly builds
‚îú‚îÄ‚îÄ SecureCodeSandboxService.swift   # CodeSandbox integration
‚îî‚îÄ‚îÄ Resources/                       # Assets and embedded HTML

XRAiAssistantTests/
‚îú‚îÄ‚îÄ ChatViewModelTests.swift         # AI integration tests
‚îú‚îÄ‚îÄ CodeSandboxIntegrationTests.swift # Sandbox tests
‚îî‚îÄ‚îÄ SecureCodeSandboxServiceTests.swift
```

### Key Dependencies

**iOS Native Stack**:
- **Swift 5.9+**: Modern language features and concurrency
- **SwiftUI**: Declarative UI framework
- **WebKit**: Web content integration
- **AIProxy Swift v0.129.0**: Together.ai + multi-provider API client
- **LlamaStackClient**: Meta Llama model integration

**Package Dependencies** ([Package.resolved](XRAiAssistant.xcodeproj/project.xcworkspace/xcshareddata/swiftpm/Package.resolved)):
- `AIProxySwift` v0.129.0 - AI provider client
- `llama-stack-client-swift` (main branch)
- Swift OpenAPI Generator stack (v1.10.3)

---

## ü§ñ AI Provider System

### Architecture Overview

XRAiAssistant uses a **multi-provider architecture** that supports multiple AI services:

**Current Providers**:
1. **Together.ai** - Primary provider (FREE and paid models)
   - DeepSeek R1 70B (FREE)
   - Meta Llama 3.3 70B (FREE)
   - Qwen 2.5 7B Turbo ($0.30/1M tokens)

2. **Google AI (Gemini)** - NEW ‚ú® (FREE tier available)
   - Gemini 2.5 Flash (Fast, extended context)
   - Gemini 2.5 Pro (Advanced reasoning, 2M context)
   - Gemini 3.0 Flash Thinking (Explicit reasoning)
   - Gemini 1.5 Flash/Pro (Stable models)

3. **Anthropic Claude** - Advanced reasoning
   - Claude Sonnet 4 (Latest high-performance)
   - Claude Opus 4 (World's best coding model)
   - Claude 3.5 Sonnet/Haiku

4. **OpenAI** - GPT models
   - GPT-4, GPT-3.5 Turbo

5. **LlamaStack** - Fallback for Meta models
   - Direct Llama model access (when enabled)

### Provider Selection Logic

From [ChatViewModel.swift:403-435](XRAiAssistant/ChatViewModel.swift#L403-L435):

```swift
private func callLlamaInference(userMessage: String, systemPrompt: String) async throws -> String {
    // 1. Try new provider system first (better error handling)
    if let provider = aiProviderManager.getProvider(for: selectedModel) {
        return try await callNewProviderSystem(userMessage: userMessage, systemPrompt: systemPrompt)
    }

    // 2. Fall back to legacy routing
    if useLlamaStackForLlamaModels && selectedModel.contains("meta-llama") {
        return try await callLlamaStackModel(userMessage: userMessage, systemPrompt: systemPrompt)
    } else {
        return try await callTogetherAIModel(userMessage: userMessage, systemPrompt: systemPrompt)
    }
}
```

### Configuration

**API Key Management**:
- Default: `"changeMe"` - Users MUST configure their API key
- Location: Settings panel (gear icon in bottom navigation)
- Storage: UserDefaults with prefix `"XRAiAssistant_APIKey_<Provider>"`

**API Key Sources**:
- Together.ai: https://api.together.ai/settings/api-keys
- Google AI: https://aistudio.google.com/apikey (FREE tier available)
- Anthropic: https://console.anthropic.com
- OpenAI: https://platform.openai.com

**Model Parameters**:
- `temperature`: 0.0-2.0 (default: 0.7) - Controls randomness
- `topP`: 0.1-1.0 (default: 0.9) - Nucleus sampling
- `maxTokens`: 4000 - Maximum response length (REQUIRED)

---

## üÜï Google AI (Gemini) Integration (2025-11-22)

### Overview

XRAiAssistant now supports Google's Gemini models through direct API integration!

**Files Added**:
- ‚úÖ [XRAiAssistant/AIProviders/GoogleAIProvider.swift](XRAiAssistant/AIProviders/GoogleAIProvider.swift)

**Files Modified**:
- ‚úÖ [XRAiAssistant/AIProviders/AIProviderManager.swift](XRAiAssistant/AIProviders/AIProviderManager.swift) - Added GoogleAIProvider
- ‚úÖ [XRAiAssistant/ContentView.swift](XRAiAssistant/ContentView.swift) - Added Google AI API key field

### Available Gemini Models

**Gemini 2.5 Series** (Latest Stable):
- `gemini-2.5-flash` - Fast model with improved performance and extended context (DEFAULT)
- `gemini-2.5-pro` - Most capable with advanced reasoning (1M token context)
- `gemini-2.5-flash-lite` - Fast, low-cost, high-performance model

**Gemini 3 Series** (Preview - Thinking Mode):
- `gemini-3-pro-preview` - Advanced reasoning with thinking mode

**Gemini 2.0 Series** (Stable):
- `gemini-2.0-flash` - Next-gen features with 1M token context

### API Configuration

**Endpoint**: `https://generativelanguage.googleapis.com/v1beta`
**Method**: POST with streaming via SSE (Server-Sent Events)
**Authentication**: API key passed as query parameter

**Get Your Free API Key**:
1. Visit https://aistudio.google.com/apikey
2. Sign in with your Google account
3. Create a new API key
4. Paste into Settings ‚Üí Google AI API Key field

**Request Format**:
```swift
{
    "contents": [
        {"role": "user", "parts": [{"text": "message"}]}
    ],
    "generationConfig": {
        "temperature": 0.7,
        "topP": 0.9,
        "maxOutputTokens": 4000
    },
    "systemInstruction": {
        "parts": [{"text": "system prompt"}]
    }
}
```

**Response Format** (SSE):
```
data: {"candidates":[{"content":{"parts":[{"text":"response"}]}}]}
```

### Features

- ‚úÖ Streaming support via Server-Sent Events
- ‚úÖ System instructions (separate from conversation)
- ‚úÖ Temperature and Top-P control
- ‚úÖ Extended context windows (up to 2M tokens for Pro)
- ‚úÖ Free tier available with generous quotas
- ‚úÖ Thinking mode support (Gemini 3.0)

### Pricing

All Gemini models offer a **FREE tier** with generous daily quotas:
- Flash models: High free quota
- Pro models: Moderate free quota
- Paid tier available for production use

See: https://ai.google.dev/pricing

---

## üåê 3D Framework Support

### Supported Frameworks

1. **Babylon.js** - Full-featured 3D engine
   - Native WebGL rendering
   - Advanced lighting and materials
   - Physics engine support

2. **React Three Fiber** - React wrapper for Three.js
   - Component-based 3D scenes
   - JSX syntax for 3D objects
   - Hooks for animations

3. **Reactylon** - React wrapper for Babylon.js
   - React components with Babylon.js power
   - Declarative 3D scene definition

4. **Three.js** - Direct Three.js integration
   - Low-level 3D control
   - Custom shaders and effects

5. **A-Frame** - Entity-component system
   - HTML-based 3D scenes
   - WebXR support

### Framework Manager

The [Library3DManager](XRAiAssistant/Library3D/Library3DManager.swift) orchestrates:
- Framework selection and switching
- Library-specific AI prompts
- Code generation templates
- Example scenes

---

## üîß Build System (BuildKit)

### Overview

Advanced build system supporting:
- **Node.js builds** - npm/webpack bundling
- **WebAssembly builds** - Rust/C++ compilation
- **Hot reload** - Live code updates
- **Build analysis** - Performance metrics

### Build Manager

From [BuildManager.swift](XRAiAssistant/BuildKit/BuildManager.swift):

```swift
class BuildManager {
    func buildProject(code: String, framework: FrameworkKind) async throws -> BuildResult {
        // Route to appropriate build service
        switch framework {
        case .node:
            return try await nodeBuildService.build(code: code)
        case .wasm:
            return try await wasmBuildService.build(code: code)
        }
    }
}
```

**Supported Build Types**:
- React Three Fiber ‚Üí Node.js build
- Reactylon ‚Üí Node.js build
- Custom frameworks ‚Üí WASM build

---

## üéØ CodeSandbox Integration

### Secure Sandbox Service

The [SecureCodeSandboxService](XRAiAssistant/SecureCodeSandboxService.swift) provides:
- **Secure code execution** - Isolated sandbox environment
- **Live preview** - Real-time 3D rendering
- **Shareable URLs** - Deploy and share creations
- **Version control** - Save and restore projects

### API Integration

**Endpoint**: `https://codesandbox.io/api/v1/sandboxes/define`
**Method**: POST with JSON body containing files structure

**Example Request**:
```swift
let files: [String: CodeSandboxFile] = [
    "package.json": CodeSandboxFile(content: packageJSON),
    "src/index.js": CodeSandboxFile(content: jsCode),
    "src/App.js": CodeSandboxFile(content: appCode)
]

let sandboxURL = try await createSandbox(files: files)
```

---

## üîê Security & Privacy

### API Key Security
- ‚úÖ Default value: `"changeMe"` prevents accidental exposure
- ‚úÖ User-configured keys stored in UserDefaults
- ‚úÖ Key validation before API calls
- ‚úÖ Helpful error messages for missing/invalid keys

### Privacy-First Architecture
- ‚úÖ All user data stays on-device
- ‚úÖ No analytics or tracking
- ‚úÖ Generated code remains private
- ‚úÖ Optional cloud deployment (user-initiated)

---

## ‚öôÔ∏è Settings Persistence

### UserDefaults Keys

All settings use the `"XRAiAssistant_"` prefix:

```swift
// API Configuration
UserDefaults.standard.set(apiKey, forKey: "XRAiAssistant_APIKey")
UserDefaults.standard.set(selectedModel, forKey: "XRAiAssistant_SelectedModel")

// AI Parameters
UserDefaults.standard.set(temperature, forKey: "XRAiAssistant_Temperature")
UserDefaults.standard.set(topP, forKey: "XRAiAssistant_TopP")

// System Prompts
UserDefaults.standard.set(systemPrompt, forKey: "XRAiAssistant_SystemPrompt")
```

### Auto-Restore on Launch

From [ChatViewModel.swift:150](XRAiAssistant/ChatViewModel.swift#L150):

```swift
init() {
    // ... initialization ...
    loadSettings()  // Auto-restore all user preferences
}
```

---

## üß™ Testing

### Test Coverage

**Unit Tests**:
- [ChatViewModelTests.swift](XRAiAssistantTests/ChatViewModelTests.swift) - AI integration tests
- SecureCodeSandboxServiceTests.swift - Sandbox API tests

**Integration Tests**:
- CodeSandboxIntegrationTests.swift - Full E2E workflow
- CodeSandboxCompleteIntegrationTests.swift - Production scenarios

### Running Tests

```bash
# Build and test
xcodebuild test \
  -project XRAiAssistant.xcodeproj \
  -scheme XRAiAssistant \
  -sdk iphonesimulator \
  -destination 'platform=iOS Simulator,name=iPad Air 11-inch (M3)'
```

---

## üöÄ Development Guidelines

### Code Standards
- **Swift Style**: SwiftUI best practices, use `@Published` for reactive properties
- **AI Integration**: Always include error handling and retry logic
- **Logging**: Use emoji prefixes for visual categorization (`üöÄ`, `‚úÖ`, `‚ùå`, `‚ö†Ô∏è`)
- **Performance**: Optimize for mobile constraints (memory, battery, network)

### AI Parameter Tuning

```swift
enum AIMode {
    case debugging    // temp: 0.2, top-p: 0.3 - Highly focused
    case balanced     // temp: 0.7, top-p: 0.9 - General purpose (DEFAULT)
    case creative     // temp: 1.2, top-p: 0.9 - Maximum innovation
    case teaching     // temp: 0.7, top-p: 0.8 - Educational explanations
}
```

### Error Handling

From [ChatViewModel.swift:368-386](XRAiAssistant/ChatViewModel.swift#L368-L386):

```swift
catch {
    if let providerError = error as? AIProviderError {
        switch providerError {
        case .configurationError(let message):
            if message.contains("API key not configured") {
                errorMessage = "‚ö†Ô∏è API Key Required: Please configure your Together.ai API key in Settings"
            }
        }
    } else if error.localizedDescription.contains("401") {
        errorMessage = "‚ö†Ô∏è Authentication Failed: Please verify your API key in Settings"
    }
}
```

**Best Practices**:
- Provide user-friendly error messages
- Include actionable next steps
- Link to API key settings
- Log technical details for debugging

---

## üì¶ Build Requirements

### Build Verification (MANDATORY)

At the end of EVERY coding session, verify the project builds:

```bash
# Quick build check (no code signing)
xcodebuild -project XRAiAssistant.xcodeproj \
  -scheme XRAiAssistant \
  -configuration Debug \
  -sdk iphonesimulator \
  build \
  CODE_SIGN_IDENTITY="" \
  CODE_SIGNING_REQUIRED=NO \
  2>&1 | grep -E "(error:|warning:|Build succeeded|BUILD FAILED)"
```

**Expected Output**: `** BUILD SUCCEEDED **`

### Xcode 15+ File Synchronization

**IMPORTANT**: This project uses Xcode 15+ automatic file system synchronization.

- ‚úÖ New Swift files are automatically included when placed in directories
- ‚úÖ No manual `.pbxproj` editing required
- ‚ùå DO NOT programmatically modify `project.pbxproj` (causes corruption)

**Recovery from Corruption**:
```bash
# If you see "duplicate GUID" errors:
./scripts/xcode_recovery.sh

# Then open Xcode to resolve packages
open XRAiAssistant.xcodeproj
```

---

## üéØ Current State (2025-11-22)

### ‚úÖ Fully Implemented
- Multi-provider AI system (Together.ai, Anthropic, LlamaStack)
- Professional parameter control (temperature, top-p, max-tokens)
- Settings persistence with auto-restore
- Multiple 3D framework support (5 frameworks)
- CodeSandbox integration for sharing
- Advanced build system with hot reload
- Comprehensive error handling
- **Together AI API 400 errors FIXED** ‚úÖ

### üöß In Development
- Local SQLite RAG system for offline knowledge
- Multi-modal AI (image input for scene analysis)
- Extended model support (more providers)

### üìã Roadmap
- Android version feature parity
- Desktop (macOS/Windows) deployment
- Community example library
- Collaborative features

---

## üêõ Common Issues & Solutions

### Issue: 400 Bad Request from Together AI
**Solution**: ‚úÖ FIXED - Added `maxTokens: 4000` parameter to all Together.ai requests

### Issue: API Key Not Configured
**Solution**:
1. Tap Settings (gear icon) in bottom navigation
2. Replace "changeMe" with your Together.ai API key
3. Get free API key at https://api.together.ai/settings/api-keys

### Issue: Empty AI Responses
**Solution**: Check that `maxTokens` is set (now default 4000)

### Issue: Build Failures
**Solution**:
1. Clean DerivedData: `rm -rf ~/Library/Developer/Xcode/DerivedData`
2. Resolve Swift packages in Xcode
3. Rebuild project

---

## üìö Additional Resources

### Documentation
- [MultiProviderSetup.md](XRAiAssistant/Documentation/MultiProviderSetup.md) - AI provider configuration
- [BugFixes.md](XRAiAssistant/Documentation/BugFixes.md) - Historical fixes
- [README.md](README.md) - Project overview

### External Links
- Together AI Docs: https://docs.together.ai
- AIProxy Swift: https://github.com/lzell/AIProxySwift
- Babylon.js: https://www.babylonjs.com
- React Three Fiber: https://docs.pmnd.rs/react-three-fiber

---

## üîÑ Version History

**2025-11-22**: Fixed Together AI 400 errors by adding `maxTokens` parameter
**2025-10-15**: Implemented Reactylon API fixes and camera setup patterns
**2025-10-14**: Added React Three Fiber CodeSandbox integration

---

**XRAiAssistant iOS** - The future of AI-powered XR development üöÄ
